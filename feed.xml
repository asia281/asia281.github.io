<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://asia281.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://asia281.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-12T16:16:56+00:00</updated><id>https://asia281.github.io/feed.xml</id><title type="html">Asia makes her first blog</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Markov equivalence class</title><link href="https://asia281.github.io/blog/2024/markov-equvalence-class/" rel="alternate" type="text/html" title="Markov equivalence class"/><published>2024-01-11T00:00:00+00:00</published><updated>2024-01-11T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/markov-equvalence-class</id><content type="html" xml:base="https://asia281.github.io/blog/2024/markov-equvalence-class/"><![CDATA[<h2 id="future-reading">Future reading:</h2> <ul> <li><a href="https://arxiv.org/pdf/1104.2808.pdf" target="_blank">Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</a></li> </ul>]]></content><author><name></name></author><category term="causality"/><summary type="html"><![CDATA[Why we can't discover]]></summary></entry><entry><title type="html">Causal interference</title><link href="https://asia281.github.io/blog/2024/do-calculus/" rel="alternate" type="text/html" title="Causal interference"/><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-02T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/do-calculus</id><content type="html" xml:base="https://asia281.github.io/blog/2024/do-calculus/"><![CDATA[<h2 id="rules">Rules</h2> <ol> <li> \[P(y | do(t),z,w) = P(y | do(t),w) if Y \perp _{G_T} Z | T,W\] </li> </ol> <p>It’s a generalization of d-separation to interventional distributions.</p> \[P(y|z,w)=P(y|w) if Y \perp _G Z|W\] <ol> <li> \[P(y | do(t),do(z),w) = P(y | do(t),z,w) if Y ?GT,Z Z | T,W\] </li> </ol> <p>It’s a generalization of backdoor adjustment/criterion</p> <table> <tbody> <tr> <td>P(y</td> <td>do(z),w)=P(y</td> <td>z,w) if Y ?GZ Z</td> <td>W</td> </tr> </tbody> </table> <ol> <li> \[P(y | do(t),do(z),w) = P(y | do(t),w) if Y \perp GT,Z(W) Z | T,W\] </li> </ol> <p>where $Z(W)$ denotes the set of nodes of $Z$ that aren’t ancestors of any node of $W$ in $G_T$.</p> \[P(y|do(z),w)=P(y|w) if Y ?GZ(W) Z|W\]]]></content><author><name></name></author><category term="causality"/><summary type="html"><![CDATA[Causal interference]]></summary></entry><entry><title type="html">Causal interference</title><link href="https://asia281.github.io/blog/2024/causal-basics/" rel="alternate" type="text/html" title="Causal interference"/><published>2024-01-01T00:00:00+00:00</published><updated>2024-01-01T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/causal-basics</id><content type="html" xml:base="https://asia281.github.io/blog/2024/causal-basics/"><![CDATA[<h3 id="sources">Sources</h3> <p>If you want to start your adventure with causality, I recommend to watch the videos from <a href="https://www.bradyneal.com/causal-inference-course" target="_blank">Causal Inference Course</a>. They honestly have the best explanations of causal theory I’ve ever seen.</p> <p>What is the primary question of causal interference?</p> <h1 id="why-is-association-not-causation">Why is association not causation?</h1> <h2 id="how-to-allow-identifiability-computing-from-purely-statistical-quantities">How to allow identifiability? (computing from purely statistical quantities)</h2> <p>Ignorability: (Y(1), Y(0)) independent T. Intuition: we ignore all missing data and compute statistics based on data we have.</p> \[E(Y(1)) - E(Y(0)) = E(Y(1)|T = 1) - E(Y(0) | T = 0) = E(Y|T = 1) - E(Y|T = 0)\] <p>Confounding disappears after adding ignorability.</p> <h1 id="exchangeability">Exchangeability:</h1> <p>We can swap the groups and we’ll get the same expected value. We can write it as:</p> \[E(Y(1) | T = 1) = E(Y(1) | T = 0)= E(Y(1))\] <p>Potential outcome Y is independent from treatment.</p> <h2 id="ranomized-control-trial-rct">Ranomized control trial (RCT)</h2> <p>Forcing people in groups to change their trial type in order to make group random. It removes confounders. Graphical interpretation: removing an edge. It makes a graph satisfy backdoor criterion. Some</p> <table> <tbody> <tr> <td>If we have covariate balance ($P(X</td> <td>T = 0) = P(X</td> <td>T = 1)$), then assosiation is causation ($P(X</td> <td>do(T)) = P (X</td> <td>T)$).</td> </tr> </tbody> </table> <h2 id="backdoor">Backdoor</h2> <h1 id="criterion">Criterion</h1> <p>To establish a causal relationship between X and Y, you need to collectively block (condition on) all backdoor paths that could introduce confounding. The backdoor criterion states that a variable set $Z$ satisfies the criterion if and only if:</p> <ol> <li>$Z$ blocks all backdoor paths from $X$ to $Y$.</li> <li>There are no colliders on the backdoor paths that are in the set $Z$.</li> </ol> <p>We can ilustrate if as follows: <img src="/assets/img/openbackdoor.svg" alt="Backdoor"/></p> <p>Let’s do some examples. Let’s consider the following graph: <img src="/assets/img/biasexamples.svg" alt="Backdoor-example"/></p> <ol> <li>$X \perp T$ Y is a collider that hasn’t been conditioned on.</li> <li>$X \nperp T | Y$ Y is a collider that has been conditioned on</li> <li>$X \nperp T | W$ W has been conditioned on, it is a descendant of a collider</li> <li>$Y \perp G$</li> <li>$Y \nperp G | U$ U is a collider that has been conditioned on</li> <li>$Y \perp G | U, T$ T is a confounder that has been conditioned on</li> </ol> <h1 id="adjustment">Adjustment</h1> <h2 id="frontdoor-criterion">Frontdoor criterion</h2> <p>Like the backdoor criterion, the front door criterion is used to identify and estimate causal relationships between variables. It is applicable when there is an unobserved or latent variable M that acts as an intermediate step between the X and the Y.</p> <p>A set of variables $M$ satisfies the frontdoor criterion relative to $T$ and $Y$ if the following are true:</p> <ol> <li>$M$ completely mediates the effectof $T$ on $Y$ (i.e. all causal paths from T to Y go through M).</li> <li>There is no unblocked backdoor path from T to M.</li> <li>All backdoor paths from M to Y are blocked by T.</li> </ol> <h1 id="adjustment-1">Adjustment</h1> <p>If $Y, M, T$ satisfy criterion and we have positivity, then: \(P(y|do(t)) = \sum_m P(m|t) \sum _{t'} P(y|m, t')P(t')\)</p> <h1 id="other-criterions">Other criterions</h1> <p><strong>Necessary criterion:</strong> For each backdoor path from $T$ to any child $M$ of $T$ that is an ancestor of $Y$, we must block the path. It’s not sufficient criterion.</p> <p><strong>Unconfounded children criterion</strong>: All backdoor paths from the treatment variable T to all of its children that are ancestors of Y with a single conditioning set must be block. Sufficient when T is a single variable.</p> <h1 id="currently-we-usually-try-to-solve-one-of-the-following-problems">Currently, we usually try to solve one of the following problems:</h1> <ol> <li> <p><strong>Causal inference</strong>: How much would some specific variables (features or the label) change if we manipulate the value of another specific variable?</p> </li> <li> <p><strong>Causal discovery</strong>: By modifying the value of which variables could we change the value of another variable?</p> </li> </ol>]]></content><author><name></name></author><category term="causality"/><summary type="html"><![CDATA[Causal interference]]></summary></entry></feed>