<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://asia281.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://asia281.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-12T16:39:59+00:00</updated><id>https://asia281.github.io/feed.xml</id><title type="html">Asia makes her first blog</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Gradient-based discovery methods</title><link href="https://asia281.github.io/blog/2024/gradient-based-discovery-methods/" rel="alternate" type="text/html" title="Gradient-based discovery methods"/><published>2024-01-12T00:00:00+00:00</published><updated>2024-01-12T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/gradient-based-discovery-methods</id><content type="html" xml:base="https://asia281.github.io/blog/2024/gradient-based-discovery-methods/"><![CDATA[<h1 id="classical-discovery-methods">Classical discovery methods</h1> <h2 id="pc">PC</h2> <h2 id="fci">FCI</h2> <p>While observational data alone is in general not sufficient to identify the DAG, interventional data can improve identifiability up to finding the exact graph. Finding the right DAG is challenging as the solution space grows super-exponentially with the number of variables.</p> <h1 id="gradient-based-discovery-methods">Gradient-based discovery methods</h1> <h2 id="enco-github">ENCO <a href="https://github.com/phlippe/ENCO" target="_blank" rel="noopener noreferrer">github</a></h2> <h2 id="dcdi">DCDI</h2> <h2 id="deci">DECI</h2> <h2 id="dibs">DiBS</h2> <h2 id="sdi">SDI</h2>]]></content><author><name></name></author><category term="sample-posts"/><category term="git"/><summary type="html"><![CDATA[Classical discovery methods]]></summary></entry><entry><title type="html">Markov equivalence class</title><link href="https://asia281.github.io/blog/2024/markov-equvalence-class/" rel="alternate" type="text/html" title="Markov equivalence class"/><published>2024-01-11T00:00:00+00:00</published><updated>2024-01-11T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/markov-equvalence-class</id><content type="html" xml:base="https://asia281.github.io/blog/2024/markov-equvalence-class/"><![CDATA[<h2 id="d-separation">d-separation</h2> <p>d-separation is a criterion for deciding, from a given a causal graph, whether a set X of variables is independent of another set Y, given a third set Z. The idea is to associate “dependence” with “connectedness” (i.e., the existence of a connecting path) and “independence” with “unconnected-ness” or “separation”. The only twist on this simple idea is to define what we mean by “connecting path”, given that we are dealing with a system of directed arrows in which some vertices (those residing in Z) correspond to measured variables, whose values are known precisely. To account for the orientations of the arrows we use the terms “d-separated” and “d-connected” (d connotes “directional”).</p> <p>We start by considering separation between two singleton variables, x and y; the extension to sets of variables is straightforward (i.e., two sets are separated if and only if each element in one set is separated from every element in the other).</p> <h3 id="rules">Rules:</h3> <ul> <li>x and y are d-connected if there is an unblocked path between them.</li> <li>If a collider is a member of the conditioning set Z, or has a descendant in Z, then it no longer blocks any path that traces this collider.</li> <li>x and y are d-connected, conditioned on a set Z of nodes, if there is a collider-free path between x and y that traverses no member of Z. If no such path exists, we say that x and y are d-separated by Z, We also say then that every path between x and y is “blocked” by Z.</li> </ul> <h2 id="markov-equivalence">Markov equivalence</h2> <p>When exactly the same set of d-separation relations hold in two directed graphs, no matter whether respectively cyclic or acyclic, we say that they are Markov equivalent.</p> <p>Two DAGs $G_1, G_2$ are Markov equivalent if and only if</p> <ol> <li>$G_1$ and $G_2$ contain the same vertices</li> <li>There is an edge between A and B in $G_1$ iff there is an edge between A and B in $G_2$;</li> <li>$G_1$ and $G_2$ have the same unshielded colliders. These conditions imply a fourth condition:</li> <li>$G_1$ and $G_2$ have the same unshielded noncolliders.</li> </ol> <pre><code class="language-mermaid">sequenceDiagram
    participant A
    participant B
    participant C
    participant D
    A-&gt;&gt;B 
    B-&gt;&gt;C
    A-&gt;&gt;C
</code></pre> <h2 id="future-reading">Future reading:</h2> <ul> <li><a href="https://arxiv.org/pdf/1104.2808.pdf" target="_blank">Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</a></li> </ul>]]></content><author><name></name></author><category term="causality"/><summary type="html"><![CDATA[Why we can't discover]]></summary></entry><entry><title type="html">Causal interference</title><link href="https://asia281.github.io/blog/2024/do-calculus/" rel="alternate" type="text/html" title="Causal interference"/><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-02T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/do-calculus</id><content type="html" xml:base="https://asia281.github.io/blog/2024/do-calculus/"><![CDATA[<h2 id="rules">Rules</h2> <ol> <li> \[P(y | do(t),z,w) = P(y | do(t),w) if Y \perp _{G_T} Z | T,W\] </li> </ol> <p>It’s a generalization of d-separation to interventional distributions.</p> \[P(y|z,w)=P(y|w) if Y \perp _G Z|W\] <ol> <li> \[P(y | do(t),do(z),w) = P(y | do(t),z,w) if Y ?GT,Z Z | T,W\] </li> </ol> <p>It’s a generalization of backdoor adjustment/criterion</p> <table> <tbody> <tr> <td>P(y</td> <td>do(z),w)=P(y</td> <td>z,w) if Y ?GZ Z</td> <td>W</td> </tr> </tbody> </table> <ol> <li> \[P(y | do(t),do(z),w) = P(y | do(t),w) if Y \perp GT,Z(W) Z | T,W\] </li> </ol> <p>where $Z(W)$ denotes the set of nodes of $Z$ that aren’t ancestors of any node of $W$ in $G_T$.</p> \[P(y|do(z),w)=P(y|w) if Y ?GZ(W) Z|W\]]]></content><author><name></name></author><category term="causality"/><summary type="html"><![CDATA[Causal interference]]></summary></entry><entry><title type="html">Causal interference</title><link href="https://asia281.github.io/blog/2024/causal-basics/" rel="alternate" type="text/html" title="Causal interference"/><published>2024-01-01T00:00:00+00:00</published><updated>2024-01-01T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/causal-basics</id><content type="html" xml:base="https://asia281.github.io/blog/2024/causal-basics/"><![CDATA[<h3 id="sources">Sources</h3> <p>If you want to start your adventure with causality, I recommend to watch the videos from <a href="https://www.bradyneal.com/causal-inference-course" target="_blank">Causal Inference Course</a>. They honestly have the best explanations of causal theory I’ve ever seen.</p> <p>What is the primary question of causal interference?</p> <h1 id="why-is-association-not-causation">Why is association not causation?</h1> <h2 id="how-to-allow-identifiability-computing-from-purely-statistical-quantities">How to allow identifiability? (computing from purely statistical quantities)</h2> <p>Ignorability: (Y(1), Y(0)) independent T. Intuition: we ignore all missing data and compute statistics based on data we have.</p> \[E(Y(1)) - E(Y(0)) = E(Y(1)|T = 1) - E(Y(0) | T = 0) = E(Y|T = 1) - E(Y|T = 0)\] <p>Confounding disappears after adding ignorability.</p> <h1 id="exchangeability">Exchangeability:</h1> <p>We can swap the groups and we’ll get the same expected value. We can write it as:</p> \[E(Y(1) | T = 1) = E(Y(1) | T = 0)= E(Y(1))\] <p>Potential outcome Y is independent from treatment.</p> <h2 id="ranomized-control-trial-rct">Ranomized control trial (RCT)</h2> <p>Forcing people in groups to change their trial type in order to make group random. It removes confounders. Graphical interpretation: removing an edge. It makes a graph satisfy backdoor criterion. Some</p> <table> <tbody> <tr> <td>If we have covariate balance ($P(X</td> <td>T = 0) = P(X</td> <td>T = 1)$), then assosiation is causation ($P(X</td> <td>do(T)) = P (X</td> <td>T)$).</td> </tr> </tbody> </table> <h2 id="backdoor">Backdoor</h2> <h1 id="criterion">Criterion</h1> <p>To establish a causal relationship between X and Y, you need to collectively block (condition on) all backdoor paths that could introduce confounding. The backdoor criterion states that a variable set $Z$ satisfies the criterion if and only if:</p> <ol> <li>$Z$ blocks all backdoor paths from $X$ to $Y$.</li> <li>There are no colliders on the backdoor paths that are in the set $Z$.</li> </ol> <p>We can ilustrate if as follows: <img src="/assets/img/openbackdoor.svg" alt="Backdoor"/></p> <p>Let’s do some examples. Let’s consider the following graph: <img src="/assets/img/biasexamples.svg" alt="Backdoor-example"/></p> <ol> <li>$X \perp T$ Y is a collider that hasn’t been conditioned on.</li> <li>$X \nperp T | Y$ Y is a collider that has been conditioned on</li> <li>$X \nperp T | W$ W has been conditioned on, it is a descendant of a collider</li> <li>$Y \perp G$</li> <li>$Y \nperp G | U$ U is a collider that has been conditioned on</li> <li>$Y \perp G | U, T$ T is a confounder that has been conditioned on</li> </ol> <h1 id="adjustment">Adjustment</h1> <h2 id="frontdoor-criterion">Frontdoor criterion</h2> <p>Like the backdoor criterion, the front door criterion is used to identify and estimate causal relationships between variables. It is applicable when there is an unobserved or latent variable M that acts as an intermediate step between the X and the Y.</p> <p>A set of variables $M$ satisfies the frontdoor criterion relative to $T$ and $Y$ if the following are true:</p> <ol> <li>$M$ completely mediates the effectof $T$ on $Y$ (i.e. all causal paths from T to Y go through M).</li> <li>There is no unblocked backdoor path from T to M.</li> <li>All backdoor paths from M to Y are blocked by T.</li> </ol> <h1 id="adjustment-1">Adjustment</h1> <p>If $Y, M, T$ satisfy criterion and we have positivity, then: \(P(y|do(t)) = \sum_m P(m|t) \sum _{t'} P(y|m, t')P(t')\)</p> <h1 id="other-criterions">Other criterions</h1> <p><strong>Necessary criterion:</strong> For each backdoor path from $T$ to any child $M$ of $T$ that is an ancestor of $Y$, we must block the path. It’s not sufficient criterion.</p> <p><strong>Unconfounded children criterion</strong>: All backdoor paths from the treatment variable T to all of its children that are ancestors of Y with a single conditioning set must be block. Sufficient when T is a single variable.</p> <h1 id="currently-we-usually-try-to-solve-one-of-the-following-problems">Currently, we usually try to solve one of the following problems:</h1> <ol> <li> <p><strong>Causal inference</strong>: How much would some specific variables (features or the label) change if we manipulate the value of another specific variable?</p> </li> <li> <p><strong>Causal discovery</strong>: By modifying the value of which variables could we change the value of another variable?</p> </li> </ol>]]></content><author><name></name></author><category term="causality"/><summary type="html"><![CDATA[Causal interference]]></summary></entry></feed>