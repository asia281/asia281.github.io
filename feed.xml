<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://asia281.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://asia281.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-11T13:43:17+00:00</updated><id>https://asia281.github.io/feed.xml</id><title type="html">Asia makes her first blog</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Markov equivalence class</title><link href="https://asia281.github.io/blog/2024/markov-equvalence-class/" rel="alternate" type="text/html" title="Markov equivalence class"/><published>2024-01-11T00:00:00+00:00</published><updated>2024-01-11T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/markov-equvalence-class</id><content type="html" xml:base="https://asia281.github.io/blog/2024/markov-equvalence-class/"><![CDATA[<h2 id="why">Why?</h2> <p>##</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[Why we can't discover]]></summary></entry><entry><title type="html">Causal interference</title><link href="https://asia281.github.io/blog/2024/do-calculus/" rel="alternate" type="text/html" title="Causal interference"/><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-02T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/do-calculus</id><content type="html" xml:base="https://asia281.github.io/blog/2024/do-calculus/"><![CDATA[<h2 id="rules">Rules</h2> <ol> <li> \[P(y | do(t),z,w) = P(y | do(t),w) if Y \perp _{G_T} Z | T,W\] </li> </ol> <p>It’s a generalization of d-separation to interventional distributions.</p> \[P(y|z,w)=P(y|w) if Y \perp _G Z|W\] <ol> <li> \[P(y | do(t),do(z),w) = P(y | do(t),z,w) if Y ?GT,Z Z | T,W\] </li> </ol> <p>It’s a generalization of backdoor adjustment/criterion</p> <table> <tbody> <tr> <td>P(y</td> <td>do(z),w)=P(y</td> <td>z,w) if Y ?GZ Z</td> <td>W</td> </tr> </tbody> </table> <ol> <li> \[P(y | do(t),do(z),w) = P(y | do(t),w) if Y \perp GT,Z(W) Z | T,W\] </li> </ol> <p>where $Z(W)$ denotes the set of nodes of $Z$ that aren’t ancestors of any node of $W$ in $G_T$.</p> \[P(y|do(z),w)=P(y|w) if Y ?GZ(W) Z|W\]]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[Causal interference]]></summary></entry><entry><title type="html">Causal interference</title><link href="https://asia281.github.io/blog/2024/causal-basics/" rel="alternate" type="text/html" title="Causal interference"/><published>2024-01-01T00:00:00+00:00</published><updated>2024-01-01T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2024/causal-basics</id><content type="html" xml:base="https://asia281.github.io/blog/2024/causal-basics/"><![CDATA[<h3 id="sources">Sources</h3> <p>If you want to start your adventure with causality, I recommend to watch the videos from <a href="https://www.bradyneal.com/causal-inference-course" target="_blank">Causal Inference Course</a>. They honestly have the best explanations of causal theory I’ve ever seen.</p> <p>What is the primary question of causal interference?</p> <h1 id="why-is-association-not-causation">Why is association not causation?</h1> <h2 id="how-to-allow-identifiability-computing-from-purely-statistical-quantities">How to allow identifiability? (computing from purely statistical quantities)</h2> <p>Ignorability: (Y(1), Y(0)) independent T. Intuition: we ignore all missing data and compute statistics based on data we have.</p> \[E(Y(1)) - E(Y(0)) = E(Y(1)|T = 1) - E(Y(0) | T = 0) = E(Y|T = 1) - E(Y|T = 0)\] <p>Confounding disappears after adding ignorability.</p> <h1 id="exchangeability">Exchangeability:</h1> <p>We can swap the groups and we’ll get the same expected value. We can write it as:</p> \[E(Y(1) | T = 1) = E(Y(1) | T = 0)= E(Y(1))\] <p>Potential outcome Y is independent from treatment.</p> <h2 id="ranomized-control-trial-rct">Ranomized control trial (RCT)</h2> <p>Forcing people in groups to change their trial type in order to make group random. It removes confounders. Graphical interpretation: removing an edge. It makes a graph satisfy backdoor criterion. Some</p> <table> <tbody> <tr> <td>If we have covariate balance ($P(X</td> <td>T = 0) = P(X</td> <td>T = 1)$), then assosiation is causation ($P(X</td> <td>do(T)) = P (X</td> <td>T)$).</td> </tr> </tbody> </table> <h2 id="backdoor">Backdoor</h2> <h1 id="criterion">Criterion</h1> <p>To establish a causal relationship between X and Y, you need to collectively block (condition on) all backdoor paths that could introduce confounding. The backdoor criterion states that a variable set $Z$ satisfies the criterion if and only if:</p> <ol> <li>$Z$ blocks all backdoor paths from $X$ to $Y$.</li> <li>There are no colliders on the backdoor paths that are in the set $Z$.</li> </ol> <p>We can ilustrate if as follows: <img src="/assets/img/openbackdoor.svg" alt="Backdoor"/></p> <p>Let’s do some examples. Let’s consider the following graph: <img src="/assets/img/biasexamples.svg" alt="Backdoor-example"/></p> <ol> <li>$X \perp T$ Y is a collider that hasn’t been conditioned on.</li> <li>$X \nperp T | Y$ Y is a collider that has been conditioned on</li> <li>$X \nperp T | W$ W has been conditioned on, it is a descendant of a collider</li> <li>$Y \perp G$</li> <li>$Y \nperp G | U$ U is a collider that has been conditioned on</li> <li>$Y \perp G | U, T$ T is a confounder that has been conditioned on</li> </ol> <h1 id="adjustment">Adjustment</h1> <h2 id="frontdoor-criterion">Frontdoor criterion</h2> <p>Like the backdoor criterion, the front door criterion is used to identify and estimate causal relationships between variables. It is applicable when there is an unobserved or latent variable M that acts as an intermediate step between the X and the Y.</p> <p>A set of variables $M$ satisfies the frontdoor criterion relative to $T$ and $Y$ if the following are true:</p> <ol> <li>$M$ completely mediates the effectof $T$ on $Y$ (i.e. all causal paths from T to Y go through M).</li> <li>There is no unblocked backdoor path from T to M.</li> <li>All backdoor paths from M to Y are blocked by T.</li> </ol> <h1 id="adjustment-1">Adjustment</h1> <p>If $Y, M, T$ satisfy criterion and we have positivity, then: \(P(y|do(t)) = \sum_m P(m|t) \sum _{t'} P(y|m, t')P(t')\)</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[Causal interference]]></summary></entry><entry><title type="html">Gradient-based discovery methods</title><link href="https://asia281.github.io/blog/2023/gradient-based-discovery-methods/" rel="alternate" type="text/html" title="Gradient-based discovery methods"/><published>2023-12-12T00:00:00+00:00</published><updated>2023-12-12T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2023/gradient-based-discovery-methods</id><content type="html" xml:base="https://asia281.github.io/blog/2023/gradient-based-discovery-methods/"><![CDATA[<h2 id="gradient-based-discovery-methods">Gradient-based discovery methods</h2> <h1 id="enco">ENCO</h1> <h1 id="dcdi">DCDI</h1> <h1 id="deci">DECI</h1> <h1 id="dibs">DiBS</h1> <h1 id="sdi">SDI</h1>]]></content><author><name></name></author><category term="sample-posts"/><category term="git"/><summary type="html"><![CDATA[Gradient-based discovery methods]]></summary></entry><entry><title type="html">Related work to GIT</title><link href="https://asia281.github.io/blog/2023/git-related-work/" rel="alternate" type="text/html" title="Related work to GIT"/><published>2023-12-12T00:00:00+00:00</published><updated>2023-12-12T00:00:00+00:00</updated><id>https://asia281.github.io/blog/2023/git-related-work</id><content type="html" xml:base="https://asia281.github.io/blog/2023/git-related-work/"><![CDATA[<h3 id="related-work">Related work</h3> <h2 id="hallucinated-gradients">Hallucinated gradients</h2> <p>Batch Active learning by Diverse Gradient Embeddings <a href="https://arxiv.org/pdf/1906.03671v2.pdf" target="_blank">BADGE</a></p> <h2 id="experimental-design--intervention-design">Experimental Design / Intervention Design</h2> <h2 id="gradient-based-causal-structure-learning">Gradient-based Causal Structure Learning</h2> <h2 id="gradients-in-active-and-curriculum-learning">Gradients in Active and Curriculum Learning</h2> <h1 id="expected-gradient-length-egl">Expected Gradient Length (EGL)</h1> <h1 id="a-batch-active-learning-method">A batch active learning method</h1> <h1 id="gradient-prediction-gain-gpg">Gradient Prediction Gain (GPG)</h1> <p>The gradient’s magnitude and is meant to be a proxy for expected learning progress</p> <h1 id="non-single-node-interventions">Non-single node interventions</h1>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[Related work to Trust your gradient -- GIT discovery method]]></summary></entry></feed>